{
  "3": {
    "inputs": {
      "seed": 644349987795544,
      "steps": 30,
      "cfg": 5,
      "sampler_name": "uni_pc",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "53",
        0
      ],
      "positive": [
        "58",
        0
      ],
      "negative": [
        "58",
        1
      ],
      "latent_image": [
        "58",
        2
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "6": {
    "inputs": {
      "text": "flat color 2d animation of a cat swimming around in circles underwater",
      "clip": [
        "49",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "Vibrant colors, overexposed, static, blurry details, subtitles, style, work, painting, picture, motionless, overall grayish, worst quality, low quality, JPEG compression artifacts, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn face, deformed, disfigured, deformed limbs, fingers fused together, still image, messy background, three legs, many people in the background, walking backwards",
      "clip": [
        "38",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "39",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "37": {
    "inputs": {
      "unet_name": "",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "38": {
    "inputs": {
      "clip_name": "umt5_xxl_fp16.safetensors",
      "type": "wan",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "39": {
    "inputs": {
      "vae_name": "wan_2.1_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "40": {
    "inputs": {
      "width": 832,
      "height": 480,
      "length": 33,
      "batch_size": 1
    },
    "class_type": "EmptyHunyuanLatentVideo",
    "_meta": {
      "title": "EmptyHunyuanLatentVideo"
    }
  },
  "48": {
    "inputs": {
      "shift": 8,
      "model": [
        "49",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "ModelSamplingSD3"
    }
  },
  "49": {
    "inputs": {
      "lora_name": "",
      "strength_model": 1,
      "strength_clip": 1,
      "model": [
        "54",
        0
      ],
      "clip": [
        "38",
        0
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "50": {
    "inputs": {
      "frame_rate": 16,
      "loop_count": 0,
      "filename_prefix": "R8_Wan",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": false,
      "trim_to_audio": false,
      "pingpong": false,
      "save_output": true,
      "images": [
        "8",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine ðŸŽ¥ðŸ…¥ðŸ…—ðŸ…¢"
    }
  },
  "53": {
    "inputs": {
      "weight": 0.2,
      "model": [
        "48",
        0
      ],
      "latent": [
        "58",
        2
      ]
    },
    "class_type": "WanVideoEnhanceAVideoKJ",
    "_meta": {
      "title": "WanVideo Enhance A Video (native)"
    }
  },
  "54": {
    "inputs": {
      "rel_l1_thresh": 0.15,
      "start_percent": 0.1,
      "end_percent": 1,
      "cache_device": "offload_device",
      "coefficients": "14B",
      "model": [
        "37",
        0
      ]
    },
    "class_type": "WanVideoTeaCacheKJ",
    "_meta": {
      "title": "WanVideo Tea Cache (native)"
    }
  },
  "55": {
    "inputs": {
      "image": "image.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "56": {
    "inputs": {
      "target_size": 644,
      "multiple_of": 28,
      "image": [
        "55",
        0
      ]
    },
    "class_type": "Width and height for scaling image to ideal resolution ðŸª´",
    "_meta": {
      "title": "Width and height for scaling image to ideal resolution ðŸª´"
    }
  },
  "57": {
    "inputs": {
      "width": [
        "56",
        0
      ],
      "height": [
        "56",
        1
      ],
      "interpolation": "lanczos",
      "method": "stretch",
      "condition": "always",
      "multiple_of": 0,
      "image": [
        "55",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ðŸ”§ Image Resize"
    }
  },
  "58": {
    "inputs": {
      "width": [
        "56",
        0
      ],
      "height": [
        "56",
        1
      ],
      "length": 33,
      "batch_size": 1,
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "vae": [
        "39",
        0
      ],
      "clip_vision_output": [
        "59",
        0
      ],
      "start_image": [
        "57",
        0
      ]
    },
    "class_type": "WanImageToVideo",
    "_meta": {
      "title": "WanImageToVideo"
    }
  },
  "59": {
    "inputs": {
      "crop": "none",
      "clip_vision": [
        "60",
        0
      ],
      "image": [
        "57",
        0
      ]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "60": {
    "inputs": {
      "clip_name": "clip_vision_h.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  }
}
